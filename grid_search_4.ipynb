{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LogisticRegression.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from util import getData_tmp\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import (BaggingClassifier,ExtraTreesClassifier, RandomForestClassifier,\n",
    "                              AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import accuracy_score  # finding scores from different classifiers\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier  # bagging\n",
    "\n",
    "def main():\n",
    "    X, Y = getData_tmp()  # X is image, Y is labels\n",
    "    X, Y = shuffle(X, Y)\n",
    "    N, D = X.shape\n",
    "    Ntrain = int(N * 0.8)\n",
    "    X_Train, Y_Train = X[:Ntrain], Y[:Ntrain]  # sets training set\n",
    "    X_Test, Y_Test = X[Ntrain:], Y[Ntrain:]  # test set\n",
    "\n",
    "    # feature reduction PCA w/o reducing dimensionality that computes min number of dimensions req to preserve 95% of training set variance\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X_Train)\n",
    "    xtrain_pca = pca.transform(X_Train)  # changes size of xtrain\n",
    "    xtest_pca = pca.transform(X_Test)\n",
    "\n",
    "    class EstimatorSelectionHelper:\n",
    "        def __init__(self, models, params):\n",
    "            if not set(models.keys()).issubset(set(params.keys())):\n",
    "                missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "                raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "            self.models = models\n",
    "            self.params = params\n",
    "            self.keys = models.keys()\n",
    "            self.grid_searches = {}\n",
    "\n",
    "        def fit(self, x, y, cv=3, n_jobs=-1, verbose=1, scoring=None, refit=False):\n",
    "            for key in self.keys:\n",
    "                print(\"Running GridSearchCV for %s.\" % key)\n",
    "                model = self.models[key]\n",
    "                params = self.params[key]\n",
    "                gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                                  verbose=verbose, scoring=scoring, refit=refit)\n",
    "                gs.fit(x, y)\n",
    "                self.grid_searches[key] = gs\n",
    "\n",
    "        def score_summary(self, sort_by='mean_score'):\n",
    "            def row(key, scores, params):\n",
    "                d = {\n",
    "                    'estimator': key,\n",
    "                    'min_score': min(scores),\n",
    "                    'max_score': max(scores),\n",
    "                    'mean_score': np.mean(scores),\n",
    "                    'std_score': np.std(scores),\n",
    "                }\n",
    "                return pd.Series({**params, **d})  # py3\n",
    "\n",
    "                # return pd.Series(dict(params.items() + d.items())) #py2.7\n",
    "\n",
    "            rows = [row(k, gsc.cv_validation_scores, gsc.parameters)\n",
    "                    for k in self.keys\n",
    "                    for gsc in self.grid_searches[k].grid_scores_]\n",
    "            df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "            columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "            columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "            return df[columns]\n",
    "\n",
    "            # using it on classification\n",
    "\n",
    "    models1 = {\n",
    "        'LogisticRegression': LogisticRegression(),\n",
    "        'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "        'RandomForestClassifier': RandomForestClassifier(),\n",
    "        'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "        'SVC': SVC(class_weight='balanced'),\n",
    "        'BaggingClassifier': BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=800,\n",
    "                                               bootstrap=True),\n",
    "    }\n",
    "\n",
    "    params1 = {\n",
    "        'LogisticRegression':{'random_state':(1,2)},\n",
    "        'ExtraTreesClassifier': {'n_estimators':(10, 500)},  # n_estimators: number of rounds/trees, 8 or 16 rounds\n",
    "        'RandomForestClassifier': {'n_estimators': (10, 500), 'random_state': [1], 'criterion': ['entropy']},\n",
    "        'AdaBoostClassifier': {'n_estimators': (10, 500)},\n",
    "        'GradientBoostingClassifier': {'n_estimators': (10, 500), 'learning_rate': [0.08, 1.0]},\n",
    "        'SVC': [\n",
    "            {'kernel': ['linear'], 'C': [1, 10]},\n",
    "            {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "        ],\n",
    "        'BaggingClassifier': {'n_estimators': (10, 500)},\n",
    "\n",
    "    }\n",
    "    helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "    helper1.fit(xtrain_pca, Y_Train, scoring='f1', n_jobs=-1, refit=True)\n",
    "    best_scores = {}\n",
    "\n",
    "    for key in helper1.keys:\n",
    "        best_scores[key] = helper1.grid_searches[key].best_params_\n",
    "\n",
    "    print(best_scores)\n",
    "    print(helper1.score_summary(sort_by='min_score'))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
